{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='안녕하세요! 저는 OpenAI에서 개발한 인공지능 언어 모델인 Assistant입니다. 다양한 주제에 대해 정보를 제공하고 질문에 답변할 수 있도록 설계되었습니다. 글쓰기, 번역, 정보 검색 등 여러 가지 작업을 도와드릴 수 있습니다. 궁금한 점이 있거나 도움이 필요하시면 언제든지 말씀해 주세요!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 14, 'total_tokens': 91, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6ec83003ad', 'id': 'chatcmpl-BERt7pwxa3fw47QcmGg1BbtGRb8RA', 'finish_reason': 'stop', 'logprobs': None} id='run-5c184756-9433-450e-979b-43175dd89912-0' usage_metadata={'input_tokens': 14, 'output_tokens': 77, 'total_tokens': 91, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "result = llm.invoke('자기 소개를 해주세요.')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 방금 소개해주셔서 민호씨라는 것을 알고 있습니다. 다른 질문이나 도움이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o', temperature=0)\n",
    "messages =[\n",
    "  SystemMessage(content='yor are a helpful assistant'),\n",
    "  HumanMessage(content='안녕하세요! 저는 민호 라고 합니다.'),\n",
    "  AIMessage(content='안녕하세요 민호씨! 어떻게 도와드릴까요?'),\n",
    "  HumanMessage(content=\"내 이름 아세요?\")\n",
    "]\n",
    "\n",
    "result = chat.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "죄송하지만, 현재 실시간으로 웹을 검색하거나 최신 뉴스를 제공할 수 있는 기능은 없습니다. 그러나 경제 뉴스에 대한 일반적인 정보를 제공하거나, 특정 주제에 대해 알고 있는 내용을 바탕으로 도움을 드릴 수 있습니다. 다른 질문이 있거나 도움이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o', temperature=0)\n",
    "messages =[\n",
    "  SystemMessage(content='yor are a helpful assistant'),\n",
    "  HumanMessage(content='부라우저를 검색해서 결과를 반환하는 기능도 있나요? 예를들어 오늘은 2025년 3월 21일인데, 오늘의 경제 뉴스 하이라이트 3개를 알려줄 수 있어?'),\n",
    "\n",
    "]\n",
    "\n",
    "result = chat.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스트리밍을 구현할 때 반드시 `streamingcallback`을 사용해야 하는 것은 아닙니다. 스트리밍은 데이터를 실시간으로 전송하고 처리하는 방법을 의미하며, 이를 구현하는 방법은 여러 가지가 있습니다. `streamingcallback`은 특정 라이브러리나 프레임워크에서 제공하는 기능일 수 있으며, 이를 사용하면 스트리밍 데이터를 처리하는 데 편리할 수 있습니다.\n",
      "\n",
      "하지만, 스트리밍을 구현하는 방법은 사용 중인 기술 스택이나 요구 사항에 따라 다를 수 있습니다. 예를 들어, 웹 애플리케이션에서는 WebSocket을 사용하여 실시간 통신을 구현할 수 있고, Node.js에서는 스트림 API를 사용할 수 있습니다. 또한, Kafka나 RabbitMQ 같은 메시지 브로커를 사용하여 스트리밍 데이터를 처리할 수도 있습니다.\n",
      "\n",
      "따라서, 스트리밍을 구현할 때는 프로젝트의 요구 사항과 사용 중인 기술 스택에 맞는 적절한 방법을 선택하는 것이 중요합니다. `streamingcallback`은 그 중 하나의 옵션일 뿐입니다."
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "  model_name = 'gpt-4o',\n",
    "  temperature=0,\n",
    "  streaming=True,\n",
    "  callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "messages = [HumanMessage(content='streaming을 하려면 streamingcallback을 이용해야만 하나요?')]\n",
    "result = chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompts\n",
    "#### prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          다음 요리의 레시피를 생각해 주세요.\n",
      "          요리 : 카레\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = '''\n",
    "          다음 요리의 레시피를 생각해 주세요.\n",
    "          요리 : {dish}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  input_variables=['dish'],\n",
    "  template=template\n",
    ")\n",
    "\n",
    "result = prompt.format(dish='카레')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='당신은 영국 요리 전문가 입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='다음 요리의 레시피를 생각해주세요 \\n\\n요리 : 고기감자조림', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat_promt = ChatPromptTemplate.from_messages([\n",
    "  SystemMessagePromptTemplate.from_template('당신은 {country} 요리 전문가 입니다.'),\n",
    "  HumanMessagePromptTemplate.from_template(\"다음 요리의 레시피를 생각해주세요 \\n\\n요리 : {dish}\")\n",
    "])\n",
    "\n",
    "messages = chat_promt.format_prompt(country='영국', dish='고기감자조림').to_messages()\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고기감자조림은 한국의 전통적인 가정식 요리로, 고기와 감자를 간장 양념에 졸여 만든 요리입니다. 다음은 고기감자조림의 기본 레시피입니다.\n",
      "\n",
      "### 재료:\n",
      "- 소고기 (양지머리 또는 사태) 300g\n",
      "- 감자 2개\n",
      "- 당근 1개\n",
      "- 양파 1개\n",
      "- 대파 1대\n",
      "- 마늘 3쪽\n",
      "- 간장 4큰술\n",
      "- 설탕 1큰술\n",
      "- 참기름 1큰술\n",
      "- 물 2컵\n",
      "- 후추 약간\n",
      "- 깨소금 약간\n",
      "\n",
      "### 조리 방법:\n",
      "\n",
      "1. **재료 준비**:\n",
      "   - 소고기는 먹기 좋은 크기로 썰어 준비합니다.\n",
      "   - 감자와 당근은 껍질을 벗기고 큼직하게 썰어줍니다.\n",
      "   - 양파는 굵게 채 썰고, 대파는 어슷하게 썰어줍니다.\n",
      "   - 마늘은 다집니다.\n",
      "\n",
      "2. **고기 밑간**:\n",
      "   - 썰어놓은 소고기에 간장 1큰술, 다진 마늘, 후추를 넣고 조물조물 무쳐 10분 정도 재워둡니다.\n",
      "\n",
      "3. **조림 준비**:\n",
      "   - 냄비에 참기름을 두르고, 양파와 대파를 넣어 볶다가 고기를 넣고 겉면이 익을 때까지 볶습니다.\n",
      "\n",
      "4. **조림**:\n",
      "   - 고기가 어느 정도 익으면 감자와 당근을 넣고 함께 볶습니다.\n",
      "   - 물 2컵을 붓고, 간장 3큰술과 설탕을 넣어 중불에서 끓입니다.\n",
      "\n",
      "5. **졸이기**:\n",
      "   - 끓기 시작하면 불을 약하게 줄이고, 뚜껑을 덮어 감자와 당근이 익을 때까지 졸입니다. 중간에 간을 보고 필요하면 간장이나 설탕을 추가합니다.\n",
      "\n",
      "6. **마무리**:\n",
      "   - 감자와 당근이 부드럽게 익으면 불을 끄고, 깨소금을 뿌려 마무리합니다.\n",
      "\n",
      "7. **서빙**:\n",
      "   - 완성된 고기감자조림을 그릇에 담아 따뜻할 때 밥과 함께 즐기세요.\n",
      "\n",
      "이 요리는 간단하면서도 깊은 맛을 내는 것이 특징입니다. 취향에 따라 청양고추를 추가해 매콤하게 즐길 수도 있습니다. 맛있게 드세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "result = chat.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OutPut Parsers\n",
    "### pydanticOutputPaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "  ingredients : list[str] = Field(description='ingredients of the dish')\n",
    "  steps : list[str] = Field(description='stepts to make the dish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"stepts to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          다음 요리의 레시피를 한국어로 반환해주세요\n",
      "          The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"stepts to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n",
      "          요리 : 카레\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = '''\n",
    "          다음 요리의 레시피를 한국어로 반환해주세요\n",
    "          {format_instructions}\n",
    "          요리 : {dish}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template,\n",
    "  input_variables=['dish'],\n",
    "  partial_variables={'format_instructions': format_instructions}  \n",
    ")\n",
    "\n",
    "formatted_prompt = prompt.format(dish='카레')\n",
    "\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"ingredients\": [\n",
      "    \"닭고기 500g\",\n",
      "    \"감자 2개\",\n",
      "    \"당근 1개\",\n",
      "    \"양파 1개\",\n",
      "    \"카레 가루 100g\",\n",
      "    \"물 500ml\",\n",
      "    \"식용유 2큰술\",\n",
      "    \"소금 약간\",\n",
      "    \"후추 약간\"\n",
      "  ],\n",
      "  \"steps\": [\n",
      "    \"닭고기는 한 입 크기로 자르고, 감자와 당근은 껍질을 벗기고 깍둑썰기 한다.\",\n",
      "    \"양파는 얇게 채썬다.\",\n",
      "    \"큰 냄비에 식용유를 두르고 중불에서 양파를 볶는다.\",\n",
      "    \"양파가 투명해지면 닭고기를 넣고 겉면이 익을 때까지 볶는다.\",\n",
      "    \"감자와 당근을 넣고 2~3분간 더 볶는다.\",\n",
      "    \"물 500ml를 붓고 끓인다.\",\n",
      "    \"물이 끓으면 불을 약하게 줄이고 카레 가루를 넣어 잘 저어준다.\",\n",
      "    \"소금과 후추로 간을 맞춘다.\",\n",
      "    \"약한 불에서 15~20분간 끓여 재료가 부드러워질 때까지 익힌다.\",\n",
      "    \"완성된 카레를 밥과 함께 낸다.\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o', temperature=0)\n",
    "messages=[HumanMessage(content=formatted_prompt)]\n",
    "output = chat.invoke(messages)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Recipe'>\n",
      "ingredients=['닭고기 500g', '감자 2개', '당근 1개', '양파 1개', '카레 가루 100g', '물 500ml', '식용유 2큰술', '소금 약간', '후추 약간'] steps=['닭고기는 한 입 크기로 자르고, 감자와 당근은 껍질을 벗기고 깍둑썰기 한다.', '양파는 얇게 채썬다.', '큰 냄비에 식용유를 두르고 중불에서 양파를 볶는다.', '양파가 투명해지면 닭고기를 넣고 겉면이 익을 때까지 볶는다.', '감자와 당근을 넣고 2~3분간 더 볶는다.', '물 500ml를 붓고 끓인다.', '물이 끓으면 불을 약하게 줄이고 카레 가루를 넣어 잘 저어준다.', '소금과 후추로 간을 맞춘다.', '약한 불에서 15~20분간 끓여 재료가 부드러워질 때까지 익힌다.', '완성된 카레를 밥과 함께 낸다.']\n"
     ]
    }
   ],
   "source": [
    "recipe = parser.parse(output.content)\n",
    "print(type(recipe))\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains\n",
    "### LLMChain - PromptTemplate, Language model, OutputParser를 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "  ingredients : list[str] = Field(description='ingredients of the dish')\n",
    "  steps : list[str] = Field(description='steps to make the dish')\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "template = ''' 다음 요리의 레피시를 한국어로 대답해줘\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "요리 : {dish}\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template = template,\n",
    "  inpit_variables=['dish'],\n",
    "  partial_variables={'format_instructions': output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_25168\\623053292.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(prompt=prompt, llm=chat, output_parser=output_parser)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"dish\": \"카레\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human:  다음 요리의 레피시를 한국어로 대답해줘\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"ingredients\\\": {\\\"description\\\": \\\"ingredients of the dish\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}, \\\"title\\\": \\\"Ingredients\\\", \\\"type\\\": \\\"array\\\"}, \\\"steps\\\": {\\\"description\\\": \\\"steps to make the dish\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}, \\\"title\\\": \\\"Steps\\\", \\\"type\\\": \\\"array\\\"}}, \\\"required\\\": [\\\"ingredients\\\", \\\"steps\\\"]}\\n```\\n\\n요리 : 카레\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatOpenAI] [3.46s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```json\\n{\\n  \\\"ingredients\\\": [\\n    \\\"카레 가루 100g\\\",\\n    \\\"감자 2개\\\",\\n    \\\"당근 1개\\\",\\n    \\\"양파 1개\\\",\\n    \\\"고기 200g\\\",\\n    \\\"물 500ml\\\",\\n    \\\"식용유 2큰술\\\",\\n    \\\"소금 약간\\\"\\n  ],\\n  \\\"steps\\\": [\\n    \\\"감자, 당근, 양파를 먹기 좋은 크기로 썬다.\\\",\\n    \\\"고기를 적당한 크기로 썬다.\\\",\\n    \\\"팬에 식용유를 두르고 양파를 볶다가 고기를 넣고 함께 볶는다.\\\",\\n    \\\"고기가 어느 정도 익으면 감자와 당근을 넣고 함께 볶는다.\\\",\\n    \\\"물 500ml를 붓고 끓인다.\\\",\\n    \\\"물이 끓으면 카레 가루를 넣고 잘 저어준다.\\\",\\n    \\\"약한 불로 줄이고 재료가 모두 익을 때까지 끓인다.\\\",\\n    \\\"소금으로 간을 맞춘다.\\\"\\n  ]\\n}\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```json\\n{\\n  \\\"ingredients\\\": [\\n    \\\"카레 가루 100g\\\",\\n    \\\"감자 2개\\\",\\n    \\\"당근 1개\\\",\\n    \\\"양파 1개\\\",\\n    \\\"고기 200g\\\",\\n    \\\"물 500ml\\\",\\n    \\\"식용유 2큰술\\\",\\n    \\\"소금 약간\\\"\\n  ],\\n  \\\"steps\\\": [\\n    \\\"감자, 당근, 양파를 먹기 좋은 크기로 썬다.\\\",\\n    \\\"고기를 적당한 크기로 썬다.\\\",\\n    \\\"팬에 식용유를 두르고 양파를 볶다가 고기를 넣고 함께 볶는다.\\\",\\n    \\\"고기가 어느 정도 익으면 감자와 당근을 넣고 함께 볶는다.\\\",\\n    \\\"물 500ml를 붓고 끓인다.\\\",\\n    \\\"물이 끓으면 카레 가루를 넣고 잘 저어준다.\\\",\\n    \\\"약한 불로 줄이고 재료가 모두 익을 때까지 끓인다.\\\",\\n    \\\"소금으로 간을 맞춘다.\\\"\\n  ]\\n}\\n```\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 229,\n",
      "                \"prompt_tokens\": 229,\n",
      "                \"total_tokens\": 458,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_90d33c15d4\",\n",
      "              \"id\": \"chatcmpl-BEsz5vS0sQKkE8JlLkihYS86B5iqw\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-7febd7fd-7419-4d49-985c-83d8e6279637-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 229,\n",
      "              \"output_tokens\": 229,\n",
      "              \"total_tokens\": 458,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 229,\n",
      "      \"prompt_tokens\": 229,\n",
      "      \"total_tokens\": 458,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_90d33c15d4\",\n",
      "    \"id\": \"chatcmpl-BEsz5vS0sQKkE8JlLkihYS86B5iqw\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LLMChain] [3.46s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "<class 'dict'>\n",
      "{'dish': '카레', 'text': Recipe(ingredients=['카레 가루 100g', '감자 2개', '당근 1개', '양파 1개', '고기 200g', '물 500ml', '식용유 2큰술', '소금 약간'], steps=['감자, 당근, 양파를 먹기 좋은 크기로 썬다.', '고기를 적당한 크기로 썬다.', '팬에 식용유를 두르고 양파를 볶다가 고기를 넣고 함께 볶는다.', '고기가 어느 정도 익으면 감자와 당근을 넣고 함께 볶는다.', '물 500ml를 붓고 끓인다.', '물이 끓으면 카레 가루를 넣고 잘 저어준다.', '약한 불로 줄이고 재료가 모두 익을 때까지 끓인다.', '소금으로 간을 맞춘다.'])}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(prompt=prompt, llm=chat, output_parser=output_parser)\n",
    "\n",
    "recipe=chain.invoke('카레')\n",
    "\n",
    "print(type(recipe))\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleSequentailChain - Chain과 Chain을 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-4o', temperature=0)\n",
    "\n",
    "cot_template='''\n",
    "다음 질문에 답하세요.\n",
    "\n",
    "질문 : {question}\n",
    "\n",
    "단계별로 생각해 봅시다.\n",
    "'''\n",
    "\n",
    "cot_prompt = PromptTemplate(\n",
    "  input_variables=['question'],\n",
    "  template = cot_template\n",
    ")\n",
    "\n",
    "cot_chain = LLMChain(llm=chat, prompt=cot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_template = '''\n",
    "다음 문장을 결론만 간단히 요약하세요\n",
    "\n",
    "{input}\n",
    "'''\n",
    "\n",
    "summarize_prompt = PromptTemplate(\n",
    "  input_variables=['input'],\n",
    "  template = summarize_template,\n",
    ")\n",
    "\n",
    "summerize_chain = LLMChain(llm=chat, prompt = summarize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SimpleSequentialChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"나는 시장에 가서 사과 10개를 사고, 이웃에게 2개, 수리공에게 2개를 줬다. 그리고 다시 사과 5개를 사서 1개를 먹었다.나는 지금 몇개의 사과를 가지고 있을까?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"나는 시장에 가서 사과 10개를 사고, 이웃에게 2개, 수리공에게 2개를 줬다. 그리고 다시 사과 5개를 사서 1개를 먹었다.나는 지금 몇개의 사과를 가지고 있을까?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\n다음 질문에 답하세요.\\n\\n질문 : 나는 시장에 가서 사과 10개를 사고, 이웃에게 2개, 수리공에게 2개를 줬다. 그리고 다시 사과 5개를 사서 1개를 먹었다.나는 지금 몇개의 사과를 가지고 있을까?\\n\\n단계별로 생각해 봅시다.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain > llm:ChatOpenAI] [2.04s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"문제를 단계별로 해결해 보겠습니다.\\n\\n1. 처음에 사과 10개를 샀습니다.\\n   - 현재 사과 개수: 10개\\n\\n2. 이웃에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 10 - 2 = 8개\\n\\n3. 수리공에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 8 - 2 = 6개\\n\\n4. 사과 5개를 추가로 샀습니다.\\n   - 현재 사과 개수: 6 + 5 = 11개\\n\\n5. 사과 1개를 먹었습니다.\\n   - 현재 사과 개수: 11 - 1 = 10개\\n\\n따라서, 현재 가지고 있는 사과의 개수는 10개입니다.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"문제를 단계별로 해결해 보겠습니다.\\n\\n1. 처음에 사과 10개를 샀습니다.\\n   - 현재 사과 개수: 10개\\n\\n2. 이웃에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 10 - 2 = 8개\\n\\n3. 수리공에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 8 - 2 = 6개\\n\\n4. 사과 5개를 추가로 샀습니다.\\n   - 현재 사과 개수: 6 + 5 = 11개\\n\\n5. 사과 1개를 먹었습니다.\\n   - 현재 사과 개수: 11 - 1 = 10개\\n\\n따라서, 현재 가지고 있는 사과의 개수는 10개입니다.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 183,\n",
      "                \"prompt_tokens\": 89,\n",
      "                \"total_tokens\": 272,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_90d33c15d4\",\n",
      "              \"id\": \"chatcmpl-BEt3NFD7eFgJQVwckaEKqXqb6mEYd\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-d03327b6-d926-4cea-b997-d7546199c8ad-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 89,\n",
      "              \"output_tokens\": 183,\n",
      "              \"total_tokens\": 272,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 183,\n",
      "      \"prompt_tokens\": 89,\n",
      "      \"total_tokens\": 272,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_90d33c15d4\",\n",
      "    \"id\": \"chatcmpl-BEt3NFD7eFgJQVwckaEKqXqb6mEYd\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain] [2.04s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"문제를 단계별로 해결해 보겠습니다.\\n\\n1. 처음에 사과 10개를 샀습니다.\\n   - 현재 사과 개수: 10개\\n\\n2. 이웃에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 10 - 2 = 8개\\n\\n3. 수리공에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 8 - 2 = 6개\\n\\n4. 사과 5개를 추가로 샀습니다.\\n   - 현재 사과 개수: 6 + 5 = 11개\\n\\n5. 사과 1개를 먹었습니다.\\n   - 현재 사과 개수: 11 - 1 = 10개\\n\\n따라서, 현재 가지고 있는 사과의 개수는 10개입니다.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"문제를 단계별로 해결해 보겠습니다.\\n\\n1. 처음에 사과 10개를 샀습니다.\\n   - 현재 사과 개수: 10개\\n\\n2. 이웃에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 10 - 2 = 8개\\n\\n3. 수리공에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 8 - 2 = 6개\\n\\n4. 사과 5개를 추가로 샀습니다.\\n   - 현재 사과 개수: 6 + 5 = 11개\\n\\n5. 사과 1개를 먹었습니다.\\n   - 현재 사과 개수: 11 - 1 = 10개\\n\\n따라서, 현재 가지고 있는 사과의 개수는 10개입니다.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\n다음 문장을 결론만 간단히 요약하세요\\n\\n문제를 단계별로 해결해 보겠습니다.\\n\\n1. 처음에 사과 10개를 샀습니다.\\n   - 현재 사과 개수: 10개\\n\\n2. 이웃에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 10 - 2 = 8개\\n\\n3. 수리공에게 사과 2개를 줬습니다.\\n   - 현재 사과 개수: 8 - 2 = 6개\\n\\n4. 사과 5개를 추가로 샀습니다.\\n   - 현재 사과 개수: 6 + 5 = 11개\\n\\n5. 사과 1개를 먹었습니다.\\n   - 현재 사과 개수: 11 - 1 = 10개\\n\\n따라서, 현재 가지고 있는 사과의 개수는 10개입니다.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain > llm:ChatOpenAI] [1.03s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"현재 가지고 있는 사과의 개수는 10개입니다.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"현재 가지고 있는 사과의 개수는 10개입니다.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 15,\n",
      "                \"prompt_tokens\": 204,\n",
      "                \"total_tokens\": 219,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEt3PxAwsV7jvdJbw6MGoIgE64BZR\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-e94d7cc7-62d2-4172-9db8-9181facc1f58-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 204,\n",
      "              \"output_tokens\": 15,\n",
      "              \"total_tokens\": 219,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 15,\n",
      "      \"prompt_tokens\": 204,\n",
      "      \"total_tokens\": 219,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEt3PxAwsV7jvdJbw6MGoIgE64BZR\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SimpleSequentialChain > chain:LLMChain] [1.03s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"현재 가지고 있는 사과의 개수는 10개입니다.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:SimpleSequentialChain] [3.07s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"현재 가지고 있는 사과의 개수는 10개입니다.\"\n",
      "}\n",
      "현재 가지고 있는 사과의 개수는 10개입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "cot_summerize_chain = SimpleSequentialChain(chains=[cot_chain, summerize_chain])\n",
    "\n",
    "result= cot_summerize_chain.invoke(\n",
    "  '나는 시장에 가서 사과 10개를 사고, 이웃에게 2개, 수리공에게 2개를 줬다. 그리고 다시 사과 5개를 사서 1개를 먹었다.'\n",
    "  '나는 지금 몇개의 사과를 가지고 있을까?'\n",
    ")\n",
    "\n",
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-6 Memory\n",
    "#### Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"안녕 나는 민호라고해\",\n",
      "  \"history\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n\\nHuman: 안녕 나는 민호라고해\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [1.13s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 49,\n",
      "                \"prompt_tokens\": 71,\n",
      "                \"total_tokens\": 120,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtMQgTZQLy3rDLNvNI480qIAP5lC\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-eaab983d-eb7b-4004-87d4-29e7ffbcdff1-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 71,\n",
      "              \"output_tokens\": 49,\n",
      "              \"total_tokens\": 120,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 49,\n",
      "      \"prompt_tokens\": 71,\n",
      "      \"total_tokens\": 120,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtMQgTZQLy3rDLNvNI480qIAP5lC\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [1.13s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\"\n",
      "}\n",
      "AI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\",\n",
      "  \"history\": \"Human: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [3.34s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 184,\n",
      "                \"prompt_tokens\": 139,\n",
      "                \"total_tokens\": 323,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtMgfEPLKB79hED5mRs1xJ3IjqCw\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f8885b51-a2b8-41ab-985c-ec9674303b26-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 139,\n",
      "              \"output_tokens\": 184,\n",
      "              \"total_tokens\": 323,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 184,\n",
      "      \"prompt_tokens\": 139,\n",
      "      \"total_tokens\": 323,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtMgfEPLKB79hED5mRs1xJ3IjqCw\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [3.34s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\"\n",
      "}\n",
      "AI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"그거 엄청 예전에 나온건데?\",\n",
      "  \"history\": \"Human: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [3.48s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 159,\n",
      "                \"prompt_tokens\": 335,\n",
      "                \"total_tokens\": 494,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtMzIScQRsRFjxKi8wemTp21omty\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-263e04df-54a1-4488-9b3e-3135e00bf0bd-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 335,\n",
      "              \"output_tokens\": 159,\n",
      "              \"total_tokens\": 494,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 159,\n",
      "      \"prompt_tokens\": 335,\n",
      "      \"total_tokens\": 494,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtMzIScQRsRFjxKi8wemTp21omty\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [3.48s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\"\n",
      "}\n",
      "AI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"그거 엄청엄청 예전에나온건데?\",\n",
      "  \"history\": \"Human: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [3.50s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 145,\n",
      "                \"prompt_tokens\": 510,\n",
      "                \"total_tokens\": 655,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtNCgsu0Gi5lvEudLturiZ9i6dww\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bc2eeadc-d062-4d93-abf2-5992755c223f-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 510,\n",
      "              \"output_tokens\": 145,\n",
      "              \"total_tokens\": 655,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 145,\n",
      "      \"prompt_tokens\": 510,\n",
      "      \"total_tokens\": 655,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtNCgsu0Gi5lvEudLturiZ9i6dww\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [3.50s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\"\n",
      "}\n",
      "AI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"그거 엄청엄청 예전에 나온거야!\",\n",
      "  \"history\": \"Human: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [2.37s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 157,\n",
      "                \"prompt_tokens\": 670,\n",
      "                \"total_tokens\": 827,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtNSU7tNIocCB5AU2sid4NPprAyJ\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-742c273f-2ed3-499d-b3b1-dd6047394eab-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 670,\n",
      "              \"output_tokens\": 157,\n",
      "              \"total_tokens\": 827,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 157,\n",
      "      \"prompt_tokens\": 670,\n",
      "      \"total_tokens\": 827,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtNSU7tNIocCB5AU2sid4NPprAyJ\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [2.37s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\"\n",
      "}\n",
      "AI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"혹시 재미있는 농담있어?\",\n",
      "  \"history\": \"Human: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\\nHuman: 혹시 재미있는 농담있어?\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [1.78s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 76,\n",
      "                \"prompt_tokens\": 839,\n",
      "                \"total_tokens\": 915,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtNlztexKZE4L8foXjfVJo25NbdQ\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ccc82367-c605-477d-8fa7-543609b188a7-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 839,\n",
      "              \"output_tokens\": 76,\n",
      "              \"total_tokens\": 915,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 76,\n",
      "      \"prompt_tokens\": 839,\n",
      "      \"total_tokens\": 915,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtNlztexKZE4L8foXjfVJo25NbdQ\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [1.78s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\"\n",
      "}\n",
      "AI: 물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \n",
      "\n",
      "왜냐하면 \"바이러스\"에 감염될 수 있으니까요! 😄\n",
      "\n",
      "혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"컴퓨터는 전자기기라서 원래도 바다에 들어가면 안되잖아\",\n",
      "  \"history\": \"Human: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\\nHuman: 혹시 재미있는 농담있어?\\nAI: 물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\\nHuman: 혹시 재미있는 농담있어?\\nAI: 물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 컴퓨터는 전자기기라서 원래도 바다에 들어가면 안되잖아\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [1.81s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 89,\n",
      "                \"prompt_tokens\": 941,\n",
      "                \"total_tokens\": 1030,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtOBm4FvRTQt4nYv4Z9HHZ317RMy\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4847194d-d0f1-4d25-a111-dacb5f6d6558-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 941,\n",
      "              \"output_tokens\": 89,\n",
      "              \"total_tokens\": 1030,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 89,\n",
      "      \"prompt_tokens\": 941,\n",
      "      \"total_tokens\": 1030,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtOBm4FvRTQt4nYv4Z9HHZ317RMy\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [1.81s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\"\n",
      "}\n",
      "AI: 맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"다른 농담해줘\",\n",
      "  \"history\": \"Human: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\\nHuman: 혹시 재미있는 농담있어?\\nAI: 물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 컴퓨터는 전자기기라서 원래도 바다에 들어가면 안되잖아\\nAI: 맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\\nHuman: 혹시 재미있는 농담있어?\\nAI: 물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 컴퓨터는 전자기기라서 원래도 바다에 들어가면 안되잖아\\nAI: 맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\\nHuman: 다른 농담해줘\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [3.58s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 프로그래머는 자연에서 길을 잃지 않을까요?\\n\\n왜냐하면 항상 \\\"트리\\\" 구조를 따라가기 때문이죠! 🌳😄\\n\\n프로그래밍 용어를 활용한 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 프로그래머는 자연에서 길을 잃지 않을까요?\\n\\n왜냐하면 항상 \\\"트리\\\" 구조를 따라가기 때문이죠! 🌳😄\\n\\n프로그래밍 용어를 활용한 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 96,\n",
      "                \"prompt_tokens\": 1039,\n",
      "                \"total_tokens\": 1135,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtON9UjKltVFw6a6LDVwyYfi9zos\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-3edc2d21-6ff5-455b-9c6e-aeba40f37334-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1039,\n",
      "              \"output_tokens\": 96,\n",
      "              \"total_tokens\": 1135,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 96,\n",
      "      \"prompt_tokens\": 1039,\n",
      "      \"total_tokens\": 1135,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtON9UjKltVFw6a6LDVwyYfi9zos\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [3.58s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 프로그래머는 자연에서 길을 잃지 않을까요?\\n\\n왜냐하면 항상 \\\"트리\\\" 구조를 따라가기 때문이죠! 🌳😄\\n\\n프로그래밍 용어를 활용한 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\"\n",
      "}\n",
      "AI: 물론이죠, 민호! 이번에는 이런 농담은 어때요?\n",
      "\n",
      "왜 프로그래머는 자연에서 길을 잃지 않을까요?\n",
      "\n",
      "왜냐하면 항상 \"트리\" 구조를 따라가기 때문이죠! 🌳😄\n",
      "\n",
      "프로그래밍 용어를 활용한 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"다른 농담 해줘\",\n",
      "  \"history\": \"Human: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\\nHuman: 혹시 재미있는 농담있어?\\nAI: 물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 컴퓨터는 전자기기라서 원래도 바다에 들어가면 안되잖아\\nAI: 맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\\nHuman: 다른 농담해줘\\nAI: 물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 프로그래머는 자연에서 길을 잃지 않을까요?\\n\\n왜냐하면 항상 \\\"트리\\\" 구조를 따라가기 때문이죠! 🌳😄\\n\\n프로그래밍 용어를 활용한 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\\nHuman: 혹시 재미있는 농담있어?\\nAI: 물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 컴퓨터는 전자기기라서 원래도 바다에 들어가면 안되잖아\\nAI: 맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\\nHuman: 다른 농담해줘\\nAI: 물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 프로그래머는 자연에서 길을 잃지 않을까요?\\n\\n왜냐하면 항상 \\\"트리\\\" 구조를 따라가기 때문이죠! 🌳😄\\n\\n프로그래밍 용어를 활용한 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 다른 농담 해줘\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [1.53s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 자바 개발자는 안경을 쓰나요?\\n\\n왜냐하면 그들은 \\\"클래스\\\"를 잘 보기 위해서죠! 🤓\\n\\n프로그래밍 관련 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 자바 개발자는 안경을 쓰나요?\\n\\n왜냐하면 그들은 \\\"클래스\\\"를 잘 보기 위해서죠! 🤓\\n\\n프로그래밍 관련 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 87,\n",
      "                \"prompt_tokens\": 1143,\n",
      "                \"total_tokens\": 1230,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 1024\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtOV1o0vx82cbzdTQweUrapmkH2e\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-95ff88d0-4e2e-46a7-9eea-bb56fd4d1c01-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1143,\n",
      "              \"output_tokens\": 87,\n",
      "              \"total_tokens\": 1230,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 1024\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 87,\n",
      "      \"prompt_tokens\": 1143,\n",
      "      \"total_tokens\": 1230,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 1024\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtOV1o0vx82cbzdTQweUrapmkH2e\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [1.53s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 자바 개발자는 안경을 쓰나요?\\n\\n왜냐하면 그들은 \\\"클래스\\\"를 잘 보기 위해서죠! 🤓\\n\\n프로그래밍 관련 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\"\n",
      "}\n",
      "AI: 물론이죠, 민호! 이번에는 이런 농담은 어때요?\n",
      "\n",
      "왜 자바 개발자는 안경을 쓰나요?\n",
      "\n",
      "왜냐하면 그들은 \"클래스\"를 잘 보기 위해서죠! 🤓\n",
      "\n",
      "프로그래밍 관련 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:ConversationChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"헉....!\",\n",
      "  \"history\": \"Human: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\\nHuman: 혹시 재미있는 농담있어?\\nAI: 물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 컴퓨터는 전자기기라서 원래도 바다에 들어가면 안되잖아\\nAI: 맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\\nHuman: 다른 농담해줘\\nAI: 물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 프로그래머는 자연에서 길을 잃지 않을까요?\\n\\n왜냐하면 항상 \\\"트리\\\" 구조를 따라가기 때문이죠! 🌳😄\\n\\n프로그래밍 용어를 활용한 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 다른 농담 해줘\\nAI: 물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 자바 개발자는 안경을 쓰나요?\\n\\n왜냐하면 그들은 \\\"클래스\\\"를 잘 보기 위해서죠! 🤓\\n\\n프로그래밍 관련 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 안녕 나는 민호라고해\\nAI: 안녕하세요, 민호! 만나서 반가워요. 저는 AI입니다. 어떻게 도와드릴까요? 요즘 관심 있는 주제가 있나요, 아니면 그냥 수다를 떨고 싶으신가요?\\nHuman: 그냥 수다나 떨어볼까? 뭐 재밌는 이야기 있어?\\nAI: 물론이죠, 민호! 요즘 기술 세계에서는 정말 흥미로운 일들이 많이 일어나고 있어요. 예를 들어, 인공지능이 예술 분야에서 점점 더 큰 역할을 하고 있다는 사실 알고 계셨나요? 최근에는 AI가 그림을 그리거나 음악을 작곡하는 데 사용되고 있어요. 예를 들어, OpenAI의 DALL-E라는 모델은 텍스트 설명을 기반으로 독창적인 이미지를 생성할 수 있답니다. 그리고 음악 쪽에서는 AI가 특정 스타일로 음악을 작곡하거나, 심지어는 유명한 작곡가의 스타일을 모방하기도 해요. 이런 기술들이 예술가들에게 새로운 영감을 주고, 창작의 경계를 넓히고 있죠. 민호는 이런 AI와 예술의 융합에 대해 어떻게 생각하세요?\\nHuman: 그거 엄청 예전에 나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었지만, 그 이후로도 계속 발전하고 있어요. 최근에는 더 정교하고 다양한 기능을 가진 버전들이 나오고 있답니다. 예를 들어, DALL-E 2는 더 높은 해상도의 이미지를 생성할 수 있고, 더 복잡한 장면도 잘 표현할 수 있어요. 그리고 AI가 예술 분야에서 활용되는 방식도 점점 다양해지고 있죠. 예술가들이 AI를 도구로 사용해 새로운 스타일을 탐구하거나, 전시회에서 AI와 협업한 작품을 선보이기도 해요. 민호는 최근에 흥미롭게 본 기술이나 트렌드가 있나요?\\nHuman: 그거 엄청엄청 예전에나온건데?\\nAI: 맞아요, DALL-E와 같은 기술은 몇 년 전에 처음 소개되었고, 그 이후로도 계속 발전하고 있어요. 기술의 발전 속도가 빠르다 보니, 몇 년 전의 기술도 이제는 꽤 오래된 것처럼 느껴질 수 있죠. 하지만 그동안 AI 기술은 다양한 분야에서 계속해서 진화하고 있고, 새로운 응용 사례들이 등장하고 있어요. 예를 들어, 최근에는 AI가 의료 분야에서 진단을 돕거나, 자율주행차 기술이 발전하는 등 여러 방면에서 혁신이 일어나고 있답니다. 민호는 혹시 다른 분야에서 관심 있는 기술이 있나요?\\nHuman: 그거 엄청엄청 예전에 나온거야!\\nAI: 맞아요, 기술의 발전 속도가 워낙 빠르다 보니 몇 년 전의 기술도 이제는 오래된 것처럼 느껴질 수 있어요. 하지만 그동안 AI와 관련된 많은 새로운 연구와 발전이 있었답니다. 예를 들어, 최근에는 양자 컴퓨팅과 AI의 결합이 주목받고 있어요. 양자 컴퓨팅은 기존의 컴퓨터로는 해결하기 어려운 문제를 빠르게 해결할 수 있는 잠재력을 가지고 있죠. 이런 기술들이 앞으로 AI의 성능을 어떻게 향상시킬지 기대가 됩니다. 민호는 혹시 양자 컴퓨팅에 대해 들어본 적 있나요, 아니면 다른 흥미로운 주제가 있나요?\\nHuman: 혹시 재미있는 농담있어?\\nAI: 물론이죠, 민호! 여기 하나 있어요: 왜 컴퓨터는 바다에 들어가면 안 될까요? \\n\\n왜냐하면 \\\"바이러스\\\"에 감염될 수 있으니까요! 😄\\n\\n혹시 더 듣고 싶은 농담이 있거나 다른 이야기를 나누고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 컴퓨터는 전자기기라서 원래도 바다에 들어가면 안되잖아\\nAI: 맞아요, 컴퓨터는 전자기기라서 물과는 정말 안 맞죠! 그래서 농담이 더 웃기게 들릴 수도 있답니다. 물과 전자기기는 정말 상극이니까요. 혹시 다른 농담이나 이야기를 듣고 싶으신가요? 아니면 다른 주제로 수다를 떨고 싶으신가요? 언제든지 말씀해 주세요!\\nHuman: 다른 농담해줘\\nAI: 물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 프로그래머는 자연에서 길을 잃지 않을까요?\\n\\n왜냐하면 항상 \\\"트리\\\" 구조를 따라가기 때문이죠! 🌳😄\\n\\n프로그래밍 용어를 활용한 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 다른 농담 해줘\\nAI: 물론이죠, 민호! 이번에는 이런 농담은 어때요?\\n\\n왜 자바 개발자는 안경을 쓰나요?\\n\\n왜냐하면 그들은 \\\"클래스\\\"를 잘 보기 위해서죠! 🤓\\n\\n프로그래밍 관련 농담이었어요. 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요!\\nHuman: 헉....!\\nAI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:ConversationChain > llm:ChatOpenAI] [1.27s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"반응이 정말 재미있네요, 민호! 😄 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요. 다양한 주제로 수다를 떨 수 있어요!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"반응이 정말 재미있네요, 민호! 😄 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요. 다양한 주제로 수다를 떨 수 있어요!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 52,\n",
      "                \"prompt_tokens\": 1236,\n",
      "                \"total_tokens\": 1288,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 1024\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "              \"id\": \"chatcmpl-BEtOjlyCPYV4IY0JdZkaKG9UbHi1h\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-0de67bb3-a35c-4d70-b323-fbcbae5f5166-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1236,\n",
      "              \"output_tokens\": 52,\n",
      "              \"total_tokens\": 1288,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 1024\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 52,\n",
      "      \"prompt_tokens\": 1236,\n",
      "      \"total_tokens\": 1288,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 1024\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_6ec83003ad\",\n",
      "    \"id\": \"chatcmpl-BEtOjlyCPYV4IY0JdZkaKG9UbHi1h\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:ConversationChain] [1.27s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"response\": \"반응이 정말 재미있네요, 민호! 😄 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요. 다양한 주제로 수다를 떨 수 있어요!\"\n",
      "}\n",
      "AI: 반응이 정말 재미있네요, 민호! 😄 혹시 더 듣고 싶은 농담이 있거나 다른 주제로 이야기하고 싶으시면 언제든지 말씀해 주세요. 다양한 주제로 수다를 떨 수 있어요!\n",
      "대화 종료\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat = ChatOpenAI(model_name='gpt-4o',temperature=0)\n",
    "conversation = ConversationChain(\n",
    "  llm=chat,\n",
    "  memory = ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "while True:\n",
    "  user_message = input(\"you : \")\n",
    "  if user_message == '끝':\n",
    "    print('대화 종료')\n",
    "    break\n",
    "\n",
    "  ai_message = conversation.invoke(input=user_message)['response']\n",
    "  print(f'AI: {ai_message}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat model에서 Memory를 사용할 때 주의할 점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: you are a helpful assistant\\nHuman: 안녕 나는 민호라고 해\\nAI: 안녕하세요 민호! 어떻게 도와드릴까요?\\nHuman: 너 내 이름 뭔지 알아?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [866ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"네, 방금 말씀해주신 대로 당신의 이름은 민호입니다. 다른 질문이나 도움이 필요하시면 언제든지 말씀해 주세요!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"네, 방금 말씀해주신 대로 당신의 이름은 민호입니다. 다른 질문이나 도움이 필요하시면 언제든지 말씀해 주세요!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 33,\n",
      "                \"prompt_tokens\": 51,\n",
      "                \"total_tokens\": 84,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_90d33c15d4\",\n",
      "              \"id\": \"chatcmpl-BEtSP2kOVij9sUxV2C0r0sE3Awdzg\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-4f13fc3f-2f69-41e8-a11a-6c5f98d7ea9a-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 51,\n",
      "              \"output_tokens\": 33,\n",
      "              \"total_tokens\": 84,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 33,\n",
      "      \"prompt_tokens\": 51,\n",
      "      \"total_tokens\": 84,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_90d33c15d4\",\n",
      "    \"id\": \"chatcmpl-BEtSP2kOVij9sUxV2C0r0sE3Awdzg\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "네, 방금 말씀해주신 대로 당신의 이름은 민호입니다. 다른 질문이나 도움이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "messages = [\n",
    "  SystemMessage(content='you are a helpful assistant'),\n",
    "  HumanMessage(content='안녕 나는 민호라고 해'),\n",
    "  AIMessage(content='안녕하세요 민호! 어떻게 도와드릴까요?'),\n",
    "  HumanMessage(content='너 내 이름 뭔지 알아?')\n",
    "]\n",
    "\n",
    "result = chat.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data connection\n",
    "#### Document loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import GitLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def file_filter(file_path):\n",
    "  return file_path.endswith('.mdx')\n",
    "\n",
    "loader = GitLoader(\n",
    "  clone_url = 'https://github.com/langchain-ai/langchain',\n",
    "  repo_path='./langchain',\n",
    "  branch='master',\n",
    "  file_filter = file_filter,\n",
    ")\n",
    "\n",
    "raw_docs = loader.load()\n",
    "print(len(raw_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 6803, which is longer than the specified 1000\n",
      "Created a chunk of size 3302, which is longer than the specified 1000\n",
      "Created a chunk of size 1851, which is longer than the specified 1000\n",
      "Created a chunk of size 1639, which is longer than the specified 1000\n",
      "Created a chunk of size 9269, which is longer than the specified 1000\n",
      "Created a chunk of size 2579, which is longer than the specified 1000\n",
      "Created a chunk of size 17814, which is longer than the specified 1000\n",
      "Created a chunk of size 1700, which is longer than the specified 1000\n",
      "Created a chunk of size 1135, which is longer than the specified 1000\n",
      "Created a chunk of size 1126, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1433, which is longer than the specified 1000\n",
      "Created a chunk of size 1300, which is longer than the specified 1000\n",
      "Created a chunk of size 1166, which is longer than the specified 1000\n",
      "Created a chunk of size 1351, which is longer than the specified 1000\n",
      "Created a chunk of size 1756, which is longer than the specified 1000\n",
      "Created a chunk of size 1643, which is longer than the specified 1000\n",
      "Created a chunk of size 1091, which is longer than the specified 1000\n",
      "Created a chunk of size 1313, which is longer than the specified 1000\n",
      "Created a chunk of size 1422, which is longer than the specified 1000\n",
      "Created a chunk of size 1662, which is longer than the specified 1000\n",
      "Created a chunk of size 1123, which is longer than the specified 1000\n",
      "Created a chunk of size 1174, which is longer than the specified 1000\n",
      "Created a chunk of size 1936, which is longer than the specified 1000\n",
      "Created a chunk of size 1441, which is longer than the specified 1000\n",
      "Created a chunk of size 1498, which is longer than the specified 1000\n",
      "Created a chunk of size 1046, which is longer than the specified 1000\n",
      "Created a chunk of size 1057, which is longer than the specified 1000\n",
      "Created a chunk of size 1363, which is longer than the specified 1000\n",
      "Created a chunk of size 1432, which is longer than the specified 1000\n",
      "Created a chunk of size 1662, which is longer than the specified 1000\n",
      "Created a chunk of size 1281, which is longer than the specified 1000\n",
      "Created a chunk of size 1752, which is longer than the specified 1000\n",
      "Created a chunk of size 1705, which is longer than the specified 1000\n",
      "Created a chunk of size 1266, which is longer than the specified 1000\n",
      "Created a chunk of size 1764, which is longer than the specified 1000\n",
      "Created a chunk of size 1378, which is longer than the specified 1000\n",
      "Created a chunk of size 1596, which is longer than the specified 1000\n",
      "Created a chunk of size 1063, which is longer than the specified 1000\n",
      "Created a chunk of size 1540, which is longer than the specified 1000\n",
      "Created a chunk of size 1888, which is longer than the specified 1000\n",
      "Created a chunk of size 1739, which is longer than the specified 1000\n",
      "Created a chunk of size 42090, which is longer than the specified 1000\n",
      "Created a chunk of size 1147, which is longer than the specified 1000\n",
      "Created a chunk of size 5835, which is longer than the specified 1000\n",
      "Created a chunk of size 1819, which is longer than the specified 1000\n",
      "Created a chunk of size 1182, which is longer than the specified 1000\n",
      "Created a chunk of size 3563, which is longer than the specified 1000\n",
      "Created a chunk of size 1053, which is longer than the specified 1000\n",
      "Created a chunk of size 1140, which is longer than the specified 1000\n",
      "Created a chunk of size 5053, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 1651, which is longer than the specified 1000\n",
      "Created a chunk of size 2096, which is longer than the specified 1000\n",
      "Created a chunk of size 8206, which is longer than the specified 1000\n",
      "Created a chunk of size 2933, which is longer than the specified 1000\n",
      "Created a chunk of size 2134, which is longer than the specified 1000\n",
      "Created a chunk of size 1915, which is longer than the specified 1000\n",
      "Created a chunk of size 1129, which is longer than the specified 1000\n",
      "Created a chunk of size 1021, which is longer than the specified 1000\n",
      "Created a chunk of size 1393, which is longer than the specified 1000\n",
      "Created a chunk of size 2357, which is longer than the specified 1000\n",
      "Created a chunk of size 2373, which is longer than the specified 1000\n",
      "Created a chunk of size 2989, which is longer than the specified 1000\n",
      "Created a chunk of size 2736, which is longer than the specified 1000\n",
      "Created a chunk of size 1123, which is longer than the specified 1000\n",
      "Created a chunk of size 1048, which is longer than the specified 1000\n",
      "Created a chunk of size 1083, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1044, which is longer than the specified 1000\n",
      "Created a chunk of size 1012, which is longer than the specified 1000\n",
      "Created a chunk of size 1438, which is longer than the specified 1000\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 1036, which is longer than the specified 1000\n",
      "Created a chunk of size 1137, which is longer than the specified 1000\n",
      "Created a chunk of size 1113, which is longer than the specified 1000\n",
      "Created a chunk of size 1337, which is longer than the specified 1000\n",
      "Created a chunk of size 1162, which is longer than the specified 1000\n",
      "Created a chunk of size 1158, which is longer than the specified 1000\n",
      "Created a chunk of size 3603, which is longer than the specified 1000\n",
      "Created a chunk of size 1330, which is longer than the specified 1000\n",
      "Created a chunk of size 1188, which is longer than the specified 1000\n",
      "Created a chunk of size 1170, which is longer than the specified 1000\n",
      "Created a chunk of size 1443, which is longer than the specified 1000\n",
      "Created a chunk of size 3138, which is longer than the specified 1000\n",
      "Created a chunk of size 1121, which is longer than the specified 1000\n",
      "Created a chunk of size 1487, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 6418, which is longer than the specified 1000\n",
      "Created a chunk of size 2028, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1175, which is longer than the specified 1000\n",
      "Created a chunk of size 1203, which is longer than the specified 1000\n",
      "Created a chunk of size 1046, which is longer than the specified 1000\n",
      "Created a chunk of size 1001, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1421\n",
      "1466\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "docs = text_splitter.split_documents(raw_docs)\n",
    "print(len(docs))\n",
    "\n",
    "\n",
    "# Created a chunk of size 6803, which is longer than the specified 1000\n",
    "# Created a chunk of size 3302, which is longer than the specified 1000\n",
    "# Created a chunk of size 1851, which is longer than the specified 1000\n",
    "# 구분자를 해주지 않아서 지정한 청크보다 크게 잘리는 애들 발생\n",
    "# 안내는 해주지만 크기가 큰 애드은 별도의 처리없이 그대로 유지된다.\n",
    "##해결하기 위해 \\n으로 구분자 추가\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separator=\"\\n\")\n",
    "\n",
    "docs = text_splitter.split_documents(raw_docs)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "[-0.01556143257766962, -0.012867593206465244, 0.021737877279520035, -0.01614966429769993, -0.024117546156048775, 0.045186977833509445, -0.019705800339579582, -0.0077606625854969025, -0.0040641543455421925, 0.022138945758342743]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "query = 'AWS의 S3에서 데이터를 읽기 위한 DocumentLoader가 있나요?'\n",
    "\n",
    "vector = embeddings.embed_query(query)\n",
    "print(len(vector))\n",
    "print(vector[:10]) #너무길어서 10개만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "db = Chroma.from_documents(docs,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11624\\2910605028.py:5: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  ccontext_dcos = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len = 4\n",
      "metadata = {'file_name': 'aws.mdx', 'file_path': 'docs\\\\docs\\\\integrations\\\\providers\\\\aws.mdx', 'file_type': '.mdx', 'source': 'docs\\\\docs\\\\integrations\\\\providers\\\\aws.mdx'}\n",
      "[Amazon DocumentDB (with MongoDB Compatibility)](https://docs.aws.amazon.com/documentdb/) is a fast, reliable, and fully managed database service. Amazon DocumentDB makes it easy to set up, operate, and scale MongoDB-compatible databases in the cloud.\n",
      "AWS offers services for computing, databases, storage, analytics, and other functionality. For an overview of all AWS services, see [Cloud Computing with Amazon Web Services](https://aws.amazon.com/what-is-aws/).\n",
      "See a [usage example](/docs/integrations/vectorstores/documentdb).\n",
      "```python\n",
      "from langchain_community.vectorstores import DocumentDBVectorSearch\n",
      "```\n",
      "### Amazon MemoryDB \n",
      "[Amazon MemoryDB](https://aws.amazon.com/memorydb/) is a durable, in-memory database service that delivers ultra-fast performance. MemoryDB is compatible with Redis OSS, a popular open source data store, \n",
      "enabling you to quickly build applications using the same flexible and friendly Redis OSS APIs, and commands that they already use today.\n"
     ]
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "\n",
    "query = \"AWS S3에서 데이터를 불러올 수 있는 Document가 있나요?\"\n",
    "\n",
    "ccontext_dcos = retriever.get_relevant_documents(query)\n",
    "print(f'len = {len(ccontext_dcos)}')\n",
    "\n",
    "first_doc = ccontext_dcos[0]\n",
    "print(f'metadata = {first_doc.metadata}')\n",
    "print(first_doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetrievalQA (Chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'AWS S3에서 데이터를 불러올 수 있는 Document가 있나요?',\n",
       " 'result': '네, AWS S3에서 데이터를 불러올 수 있는 Document Loader가 있습니다. `S3DirectoryLoader`와 `S3FileLoader`를 사용하여 AWS S3에서 데이터를 불러올 수 있습니다. 이들은 각각 S3 디렉토리와 파일을 로드하는 데 사용됩니다.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o', temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever = retriever)\n",
    "qa_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\seSac_env\\lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m현재 디렉터리에 있는 파일 목록을 확인하기 위해서는 터미널 명령어를 사용해야 합니다. \n",
      "\n",
      "Action: terminal\n",
      "Action Input: dir\u001b[0mExecuting command:\n",
      " dir\n",
      "\u001b[36;1m\u001b[1;3m Volume in drive C has no label.\n",
      " Volume Serial Number is 949F-ACE7\n",
      "\n",
      " Directory of c:\\Users\\user\\Desktop\\SeSac_projects\\LLM\\Chat_gpt\n",
      "\n",
      "2025-03-20  오후 07:44    <DIR>          .\n",
      "2025-03-20  오전 11:10    <DIR>          ..\n",
      "2025-03-25  오전 11:08               408 .env\n",
      "2025-03-20  오후 07:53                 4 .gitignore\n",
      "2025-03-21  오후 02:40            21,325 chat_gpt_prac.ipynb\n",
      "2025-03-25  오전 11:16            35,953 Lang_chain.ipynb\n",
      "               4 File(s)         57,690 bytes\n",
      "               2 Dir(s)  282,092,892,160 bytes free\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\seSac_env\\lib\\site-packages\\langchain_community\\tools\\shell\\tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m현재 디렉터리에는 다음과 같은 파일들이 있습니다:\n",
      "\n",
      "1. .env\n",
      "2. .gitignore\n",
      "3. chat_gpt_prac.ipynb\n",
      "4. Lang_chain.ipynb\n",
      "\n",
      "이 디렉터리에는 총 4개의 파일이 있으며, 두 개의 하위 디렉터리가 있습니다.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: 현재 디렉터리에는 다음과 같은 파일들이 있습니다:\n",
      "\n",
      "1. .env\n",
      "2. .gitignore\n",
      "3. chat_gpt_prac.ipynb\n",
      "4. Lang_chain.ipynb\n",
      "\n",
      "총 4개의 파일이 있으며, 두 개의 하위 디렉터리가 있습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() \n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4o', temperature=0)\n",
    "tools = load_tools(['terminal'], allow_dangerous_tools=True)\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "result=agent_executor.invoke({'input': \"현재 디렉터리에 있는 파일 목록 알려줘\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 디렉터리에는 다음과 같은 파일들이 있습니다:\n",
      "\n",
      "1. .env\n",
      "2. .gitignore\n",
      "3. chat_gpt_prac.ipynb\n",
      "4. Lang_chain.ipynb\n",
      "\n",
      "총 4개의 파일이 있으며, 두 개의 하위 디렉터리가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\seSac_env\\lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.agents import create_react_agent,AgentExecutor\n",
    "from langchain import hub\n",
    "\n",
    "def my_super_func(param):\n",
    "  return 42\n",
    "\n",
    "tools = [\n",
    "  Tool.from_function(\n",
    "    func = my_super_func,\n",
    "    name='The Answer',\n",
    "    description = '생명, 우주, 그리고 모든 것에 대한 질문의 답'\n",
    "  )\n",
    "]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': ' 이 세계의 진리를 알려줘봐', 'output': '이 세계의 진리는 42입니다.'}\n"
     ]
    }
   ],
   "source": [
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools = tools, verbos=True)\n",
    "result = agent_executor.invoke({'input' : ' 이 세계의 진리를 알려줘봐'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "\n",
    "summarize_template = '''\n",
    "아래의 글을 결론만 한마디로 요약해서 전달해\n",
    "\n",
    "{input}\n",
    "\n",
    "'''\n",
    "\n",
    "summarize_prompt = PromptTemplate(\n",
    "  input_variables=['input'],\n",
    "  template = summarize_template,\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model = 'gpt-4o', temperature=0)\n",
    "summerize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n",
    "\n",
    "tools = [\n",
    "  Tool.from_function(\n",
    "    func=summerize_chain.run,\n",
    "    name='Summarizer',\n",
    "    description='Text, Summarizer'\n",
    "  )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Summarizer\n",
      "Action Input: \"안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다. 제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다. 질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\"\u001b[0m\u001b[36;1m\u001b[1;3m저는 AI 언어 모델 ChatGPT로, 다양한 주제에 대해 대화하고 질문에 답변할 수 있습니다.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: 저는 AI 언어 모델 ChatGPT로, 다양한 주제에 대해 대화하고 질문에 답변할 수 있습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '\\n다음을 요약해 주세요.\\n\"안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. \\n저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다. 제 트레이닝 데이\\n터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드\\n리기 위해 노력할 것입니다. 질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\"\\n', 'output': '저는 AI 언어 모델 ChatGPT로, 다양한 주제에 대해 대화하고 질문에 답변할 수 있습니다.'}\n"
     ]
    }
   ],
   "source": [
    "agent = create_react_agent(llm,tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "text = '''\n",
    "다음을 요약해 주세요.\n",
    "\"안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. \n",
    "저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다. 제 트레이닝 데이\n",
    "터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드\n",
    "리기 위해 노력할 것입니다. 질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\"\n",
    "'''\n",
    "\n",
    "result = agent_executor.invoke({'input' : text})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 AI 언어 모델 ChatGPT로, 다양한 주제에 대해 대화하고 질문에 답변할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.get('output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function calling을 사용하는 Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\seSac_env\\lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `terminal` with `{'commands': 'dir'}`\n",
      "\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " ['dir']\n",
      "\u001b[36;1m\u001b[1;3m Volume in drive C has no label.\n",
      " Volume Serial Number is 949F-ACE7\n",
      "\n",
      " Directory of c:\\Users\\user\\Desktop\\SeSac_projects\\LLM\\Chat_gpt\n",
      "\n",
      "2025-03-25  오후 05:10    <DIR>          .\n",
      "2025-03-20  오전 11:10    <DIR>          ..\n",
      "2025-03-25  오전 11:08               408 .env\n",
      "2025-03-20  오후 07:53                 4 .gitignore\n",
      "2025-03-21  오후 02:40            21,325 chat_gpt_prac.ipynb\n",
      "2025-03-25  오후 05:11    <DIR>          langchain\n",
      "2025-03-25  오후 07:13           237,562 Lang_chain.ipynb\n",
      "               4 File(s)        259,299 bytes\n",
      "               3 Dir(s)  281,650,311,168 bytes free\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\seSac_env\\lib\\site-packages\\langchain_community\\tools\\shell\\tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m현재 디렉터리에 있는 파일과 폴더 목록은 다음과 같습니다:\n",
      "\n",
      "파일:\n",
      "- `.env` (408 bytes)\n",
      "- `.gitignore` (4 bytes)\n",
      "- `chat_gpt_prac.ipynb` (21,325 bytes)\n",
      "- `Lang_chain.ipynb` (237,562 bytes)\n",
      "\n",
      "폴더:\n",
      "- `langchain`\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "tools = load_tools(['terminal'], allow_dangerous_tools=True)\n",
    "prompt = hub.pull('hwchase17/openai-functions-agent')\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "result = agent_executor.invoke({'input' : '현재 디렉터리에 있는 파일 목록 알려줘'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 디렉터리에 있는 파일과 폴더 목록은 다음과 같습니다:\n",
      "\n",
      "파일:\n",
      "- `.env` (408 bytes)\n",
      "- `.gitignore` (4 bytes)\n",
      "- `chat_gpt_prac.ipynb` (21,325 bytes)\n",
      "- `Lang_chain.ipynb` (237,562 bytes)\n",
      "\n",
      "폴더:\n",
      "- `langchain`\n"
     ]
    }
   ],
   "source": [
    "print(result.get('output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "langchain.debug = True\n",
    "langchain.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\seSac_env\\lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': '서울 날씨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m서울 (Seoul) ☀ 10일 기간 일기예보, 기상 정보, 웹카메라 화면, 일출 및 일몰, 지역의 풍속 및 강수량 ... 현재 날씨 ; 예보 ; 해와 달 ; 14.6 °C : 바람 9 km/h 기압 ... 부분적으로 흐린 날씨 바람: 산들 바람 , 남서 , 속도 4 초당 미터 돌풍: 9 초당 미터 상대 습도: 83% 흐림: 28% 기압: 1011 고전력 증폭기 가시성: 100% Weather forecast for Seoul for the next 10 days. Today's weather forecast for Seoul by the hour. 서울 시민 여러분, 그리고 서울을 방문 예정인 모든 분들을 위한 최신 서울 날씨 완벽 가이드입니다! 🌞🌧️💨변덕스러운 서울 날씨, 이제 더 이상 걱정하지 마세요. 이 글 하나로 오늘, 내일, 모레 단기 예보부터 주간, 월간 장기 예보까지, 필요한 모든 날씨 정보를 한눈에 확인하고 스마트하게 ...\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': '대전 날씨'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m뉴스인사이드에서 대전 중구 오늘의 지역날씨를 알려드립니다. 2025년 3월 25일 14시 대전 중구(측정지역 : 대전광역시 중구) 현재 기온은 25.4°, 현재습도는 18% 입니다. 오늘의 최저기온은 10°, 최고기온은 24° 되겠습니다 (대전ㆍ충남=뉴스1) 양상인 기자 = 25일 대전·충남은 가끔 구름 많겠으며, 바람이 강하고 대기가 매우 건조하겠다.기상청에 따르면 이날 대전·충남 아침 최저기온은 5~10도로 예상되며, 낮 최고기온은 15~24도 분포를 나타낸다.지역별 최저기온은 대전 10도, 공주·논.. (대전/국제뉴스) 김태수 기자 = 기상청은 \"대전/충남지역은 건조특보가 발효된 가운데 오늘(25일)까지 바람이 순간풍속 55km/h(15m/s) 내외로 강하게 부는 곳이 많겠다\"고 예보했다.특히, 충남권은 대기가 건조하겠고, 바람도 강하게 불면서 작은 불씨가 큰불로 번질 수 있겠으니, 산불 등 각종 화재예방에 ... [CBC뉴스] 대전과 세종, 충남 지역 주민들은 오늘 강한 바람과 미세먼지의 이중고에 대비해야 할 것으로 보인다. 기상청에 따르면, 25일 화요일 아침 이들 지역은 가끔 구름이 많고 대기가 매우 건조하며 강한 바람이 불 것으로 예보됐다. 대전의 아침 기온은 11.3도, 천안 11.5도, 보령 9.2도, 부여 10.7도로 ... [날씨] 대전·세종·충남 내일 새벽까지 비·눈…갈수록 추워 ... 뉴스7(대전) 현재 우리 지역에 비구름이 지나고 있습니다. 밤에는 내륙을 중심으로 비와 눈이 섞여 내리겠고요. 내일 새벽까지 이어지겠습니다.\u001b[0m\u001b[32;1m\u001b[1;3m현재 서울의 날씨는 약 14.6°C로 부분적으로 흐린 상태이며, 바람은 남서쪽에서 산들바람이 불고 있습니다. 상대 습도는 83%입니다.\n",
      "\n",
      "대전의 현재 기온은 약 25.4°C이며, 습도는 18%입니다. 대전 지역은 가끔 구름이 많고 바람이 강하게 불고 있으며, 대기가 매우 건조한 상태입니다. 최저 기온은 10°C, 최고 기온은 24°C로 예상됩니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o', temperature=0)\n",
    "tools = load_tools(['ddg-search'])\n",
    "prompt = hub.pull('hwchase17/openai-functions-agent')\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools= tools, verbose=True)\n",
    "\n",
    "result = agent_executor.invoke({'input':'서울과 대전의 날씨를 알려줘'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 서울의 날씨는 약 14.6°C로 부분적으로 흐린 상태이며, 바람은 남서쪽에서 산들바람이 불고 있습니다. 상대 습도는 83%입니다.\n",
      "\n",
      "대전의 현재 기온은 약 25.4°C이며, 습도는 18%입니다. 대전 지역은 가끔 구름이 많고 바람이 강하게 불고 있으며, 대기가 매우 건조한 상태입니다. 최저 기온은 10°C, 최고 기온은 24°C로 예상됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.get('output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Tools Agent\n",
    "#### - openAI API는 functions를 더이상 사용하지 않고 tools를 사용한다.\n",
    "#### - tool API를 사용하면 모델에서 여러 함수를 한번에 호출하도록 요청할 수 있어 응답시간을 줄일 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\seSac_env\\lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': 'Seoul weather'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mWeather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Seoul area. 12 day Seoul Weather Forecast. Live Weather Warnings, hourly weather updates. Accurate Seoul weather today, forecast for sun, rain, wind and temperature. Seoul - Weather forecast from Theweather.com. Weather conditions with updates on temperature, humidity, wind speed, snow, pressure, etc. for Seoul, South Korea Seoul, South Korea - Current temperature and weather conditions. Detailed hourly weather forecast for today - including weather conditions, temperature, pressure, humidity, precipitation, dewpoint, wind, visibility, and UV index data. Seoul 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_search` with `{'query': 'Daejeon weather'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mGet the current and forecast weather for Daejeon, a city in South Korea. See temperature, precipitation, wind, pressure, humidity, and more for today and the next 10 days. Daejeon, South Korea - Current temperature and weather conditions. Detailed hourly weather forecast for today - including weather conditions, temperature, pressure, humidity, precipitation, dewpoint, wind, visibility, and UV index data. Current weather in Daejeon and forecast for today, tomorrow, and next 14 days 12 day Daejeon Weather Forecast. Live Weather Warnings, hourly weather updates. Accurate Daejeon weather today, forecast for sun, rain, wind and temperature. Get the latest weather information for Daejeon, including temperature, precipitation, wind, humidity, and more. See the hourly and daily forecast for the next 14 days, as well as the monthly averages and extremes for the year.\u001b[0m\u001b[32;1m\u001b[1;3m현재 서울과 대전의 날씨 정보를 요약해 드리겠습니다.\n",
      "\n",
      "### 서울 날씨\n",
      "- **현재 기온 및 날씨 조건**: 서울의 현재 기온과 날씨 조건을 확인할 수 있습니다.\n",
      "- **예보**: 12일간의 날씨 예보를 제공하며, 일별로 기온, 강수량, 바람, 습도 등의 정보를 확인할 수 있습니다.\n",
      "- **기타 정보**: 기압, 이슬점, 가시거리, 자외선 지수 등의 세부 정보도 제공됩니다.\n",
      "\n",
      "### 대전 날씨\n",
      "- **현재 기온 및 날씨 조건**: 대전의 현재 기온과 날씨 조건을 확인할 수 있습니다.\n",
      "- **예보**: 10일간의 날씨 예보를 제공하며, 일별로 기온, 강수량, 바람, 습도 등의 정보를 확인할 수 있습니다.\n",
      "- **기타 정보**: 기압, 이슬점, 가시거리, 자외선 지수 등의 세부 정보도 제공됩니다.\n",
      "\n",
      "더 구체적인 날씨 정보가 필요하시면, 날씨 관련 웹사이트나 앱을 통해 실시간으로 확인하실 수 있습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o', temperature=0)\n",
    "tools = load_tools(['ddg-search'])\n",
    "prompt = hub.pull('hwchase17/openai-functions-agent')\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools= tools, verbose=True)\n",
    "\n",
    "result = agent_executor.invoke({'input':'서울과 대전의 날씨를 알려줘'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 서울과 대전의 날씨 정보를 요약해 드리겠습니다.\n",
      "\n",
      "### 서울 날씨\n",
      "- **현재 기온 및 날씨 조건**: 서울의 현재 기온과 날씨 조건을 확인할 수 있습니다.\n",
      "- **예보**: 12일간의 날씨 예보를 제공하며, 일별로 기온, 강수량, 바람, 습도 등의 정보를 확인할 수 있습니다.\n",
      "- **기타 정보**: 기압, 이슬점, 가시거리, 자외선 지수 등의 세부 정보도 제공됩니다.\n",
      "\n",
      "### 대전 날씨\n",
      "- **현재 기온 및 날씨 조건**: 대전의 현재 기온과 날씨 조건을 확인할 수 있습니다.\n",
      "- **예보**: 10일간의 날씨 예보를 제공하며, 일별로 기온, 강수량, 바람, 습도 등의 정보를 확인할 수 있습니다.\n",
      "- **기타 정보**: 기압, 이슬점, 가시거리, 자외선 지수 등의 세부 정보도 제공됩니다.\n",
      "\n",
      "더 구체적인 날씨 정보가 필요하시면, 날씨 관련 웹사이트나 앱을 통해 실시간으로 확인하실 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.get('output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fuction calling을 활용한 OutputParser, Extracting,, Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': \"\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\\n\", 'text': [{'person_name': 'Alex', 'person_height': 5, 'person_hair_color': 'blonde', 'dog_name': 'Frosty', 'dog_bread': 'labrador'}, {'person_name': 'Claudia', 'person_height': 6, 'person_hair_color': 'brunette'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "schema = {\n",
    "  'properties' :{\n",
    "    'person_name' : {'type':'string'},\n",
    "    'person_height' : {'type' : 'integer'},\n",
    "    'person_hair_color' : {'type' : 'string'},\n",
    "    'dog_name' : {'type': 'string'},\n",
    "    'dog_bread' : {'type' : 'string'}\n",
    "  },\n",
    "  'required' : ['person_name', 'person_height']\n",
    "}\n",
    "\n",
    "text= '''\n",
    "Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
    "Alex's dog Frosty is a labrador and likes to play hide and seek.\n",
    "'''\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "chain = create_extraction_chain(schema, chat)\n",
    "\n",
    "people = chain.invoke(text)\n",
    "print(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"input\": \"\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\\n\",\n",
      "  \"text\": [\n",
      "    {\n",
      "      \"person_name\": \"Alex\",\n",
      "      \"person_height\": 5,\n",
      "      \"person_hair_color\": \"blonde\",\n",
      "      \"dog_name\": \"Frosty\",\n",
      "      \"dog_bread\": \"labrador\"\n",
      "    },\n",
      "    {\n",
      "      \"person_name\": \"Claudia\",\n",
      "      \"person_height\": 6,\n",
      "      \"person_hair_color\": \"brunette\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(people, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:QAEvalChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"나는 시장에 가서 사과 10가를 사고 사과 2개를 이웃에게 주고, 2개를 수리공에게 주고, 그다음 사과를 5개 사고 사과 한개를 먹었어 그럼 몇개가 남았을까?\",\n",
      "  \"answer\": \"10개\",\n",
      "  \"result\": \"먼저 사과 10개로 시작했고, 이웃에게 2개, 수리공에게 2개를 줬으니까 6개 남았고,그 다음 사과 5개를 더 사서 11개가 됐지, 그 다음에 사과를 1개 먹었으니까 이제 사과 10개가 남았어\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:QAEvalChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a teacher grading a quiz.\\nYou are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\\n\\nExample Format:\\nQUESTION: question here\\nSTUDENT ANSWER: student's answer here\\nTRUE ANSWER: true answer here\\nGRADE: CORRECT or INCORRECT here\\n\\nGrade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \\n\\nQUESTION: 나는 시장에 가서 사과 10가를 사고 사과 2개를 이웃에게 주고, 2개를 수리공에게 주고, 그다음 사과를 5개 사고 사과 한개를 먹었어 그럼 몇개가 남았을까?\\nSTUDENT ANSWER: 먼저 사과 10개로 시작했고, 이웃에게 2개, 수리공에게 2개를 줬으니까 6개 남았고,그 다음 사과 5개를 더 사서 11개가 됐지, 그 다음에 사과를 1개 먹었으니까 이제 사과 10개가 남았어\\nTRUE ANSWER: 10개\\nGRADE:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:QAEvalChain > llm:ChatOpenAI] [844ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"CORRECT\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"CORRECT\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 339,\n",
      "                \"total_tokens\": 342,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4-0613\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"chatcmpl-BEwQGjLB00P9p3317owtSE7icQTNt\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-7ac7d53a-d195-4f2f-8a48-dafa62093e45-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 339,\n",
      "              \"output_tokens\": 3,\n",
      "              \"total_tokens\": 342,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 339,\n",
      "      \"total_tokens\": 342,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4-0613\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"id\": \"chatcmpl-BEwQGjLB00P9p3317owtSE7icQTNt\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:QAEvalChain] [847ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"results\": \"CORRECT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.debug = True\n",
    "langchain.verbose = False\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "evaluator = load_evaluator('qa', eval_llm=chat)\n",
    "result = evaluator.evaluate_strings(input = '나는 시장에 가서 사과 10가를 사고 사과 2개를 이웃에게 주고, '\n",
    "                                            '2개를 수리공에게 주고, 그다음 사과를 5개 사고 사과 한개를 먹었어 그럼 몇개가 남았을까?',\n",
    "                                      prediction='먼저 사과 10개로 시작했고, 이웃에게 2개, 수리공에게 2개를 줬으니까 6개 남았고,'\n",
    "                                      '그 다음 사과 5개를 더 사서 11개가 됐지, 그 다음에 사과를 1개 먹었으니까 이제 사과 10개가 남았어',\n",
    "                                      reference='10개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'CORRECT', 'value': 'CORRECT', 'score': 1}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========혼자 랭체인 연습해보기============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ChromaSox \n",
      "2. Spectrum Feet \n",
      "3. Colorful Steps \n",
      "4. Rainbow Threads \n",
      "5. Vibrant Verve Socks\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "#프롬프트 템플릿 정의\n",
    "prompt = PromptTemplate(\n",
    "  input_variables=['product'],\n",
    "  template='what is a good name for a company that makes {product}? give me 5 names'\n",
    ")\n",
    "\n",
    "#LLM초기화\n",
    "llm = ChatOpenAI(model_name='gpt-4', temperature=0.7)\n",
    "\n",
    "#체인 생성\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "#체인 실행\n",
    "result = chain.run('colorful socks')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jOebxI%2BBJ4iMI50sBb83mOoY0tJDYf%2FRIZGHOVTb2IYn7bBLfEA%2Be9XRL4Q4kDf7DbMatuUBBqJcoWfoKjLnag%3D%3D\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "weather_key = os.getenv('WEATHER_KEY')\n",
    "\n",
    "\n",
    "print(weather_key)\n",
    "#날씨정보 가지고 오는 함수 정의\n",
    "def get_weather(city : str) -> str:\n",
    "  '기상청 API를 사용하여 날씨 정보를 가져옵니다.'\n",
    "  url = f'http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst?serviceKey={weather_key}&'\n",
    "  params ={'pageNo' : '1', \n",
    "            'numOfRows' : '1000', \n",
    "            'dataType' : 'json', \n",
    "            'base_date' : '20250321', \n",
    "            'base_time' : '0600',\n",
    "            'nx' : '55', \n",
    "            'ny' : '127' }\n",
    "  response = requests.get(url, params=params)\n",
    "  if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(response.text)\n",
    "  else : \n",
    "    print('응답을 받을 수 없습니다.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트러블 슈팅\n",
    "개ㅐㅐㅐㅐㅐㅐㅐㅐ 열받는 `SERVICE_KEY_IS_NOT_REGISTERED_ERROR` 해결했다.<br>\n",
    "가장 큰 문제는 requests.get(url,param)으로 값을 넘기면 계속해서 키 에러가 난다는것.<br>\n",
    "열받아서 그냥 param으로 안하고 url에 넣으면 정상작동...왜?<br>\n",
    "\n",
    "계속 알아보니 reqeusts.get( )의 params값만 인코딩 된다 (URL-safe 형식) <br>\n",
    "그래서 params에 인코딩 된 서비스 키를 넣으면 중복인코딩되어 이상한 키 값이 들어가서 `SERVICE_KEY_IS_NOT_REGISTERED_ERROR` 가 반환.... 열받는다<br>\n",
    "\n",
    "그냥 url에 넣어서 써도 되겠지만 왜 저런되고 이건안되는지 너무너무 알아보고싶어서 계속팠다...<br>\n",
    "params가 자동으로 인코딩 된다고하니, 디코딩 서비스키를 넣었더니 왜 또안되...?<br>\n",
    "\n",
    "문의넣어봣는데,<br>\n",
    "반영되려면 조금 걸린다고 재발급 받지말고 기다리라고하더라...<br>\n",
    "배는 고프고 짜증나서 두번 재발급받았는데...<br>\n",
    "\n",
    "그냥 밥먹고 와서 다시 해보니까 잘된다...<br>\n",
    "해피..엔딩?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seSac_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
