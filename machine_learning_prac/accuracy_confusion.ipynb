{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "  #fit( ) 메소드는 아무것도 학습하지 않음\n",
    "  def fit(self, X, y=None):\n",
    "    pass\n",
    "\n",
    "#predict 함수는 Sex피처가 1이면 0 그렇지 않으면 1로 예측함.\n",
    "  def predict (self, X):\n",
    "    pred = np.zeros((X.shape[0],1))\n",
    "    for i in range(X.shape[0]):\n",
    "      if X['Sex'].iloc[i]== 1:\n",
    "        pred[i] = 0\n",
    "      else:\n",
    "        pred[i] = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#null 처리 함수\n",
    "def fillna(df):\n",
    "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "  df['Cabin'].fillna('N', inplace=True)\n",
    "  df['Embarked'].fillna('N',inplace=True)\n",
    "  df['Fare'].fillna(0, inplace=True)\n",
    "  return df\n",
    "  \n",
    "#머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "  df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "  return df\n",
    "\n",
    "#레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "  df['Cabin'] = df['Cabin'].str[:1]\n",
    "  features = ['Cabin', 'Sex', 'Embarked']\n",
    "  for feature in features:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(df[feature])\n",
    "    df[feature] = le.transform(df[feature])\n",
    "  return df\n",
    "\n",
    "#Data Preprocessing 호출\n",
    "def transform_feature(df):\n",
    "  df = fillna(df)\n",
    "  df = drop_features(df)\n",
    "  df = format_features(df)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classification의 정확도는 0.7263\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#원본 데이터 재 로딩, 데이터 가공, 학습데이터/테스트데이터 분할\n",
    "titanic_df = pd.read_csv('./data_set/titanic_train.csv')\n",
    "y_df = titanic_df['Survived']\n",
    "x_df = titanic_df.drop('Survived', axis=1)\n",
    "x_df = transform_feature(x_df)\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(x_df,y_df, test_size=0.2, random_state=44)\n",
    "\n",
    "#더미 분류기를 이용하여 학습/예측/평가 수행\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print(f'Dummy Classification의 정확도는 {accuracy_score(y_test, mypredictions):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits data shape (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "### digits target shape (1797,)\n"
     ]
    }
   ],
   "source": [
    "class MyFakeClassifier (BaseEstimator):\n",
    "  def fit(self, X, y):\n",
    "    pass\n",
    "  \n",
    "  #입력값으로 들어오는 X데이터셋의 크기만큼 모두 0값으로 만들어서 반환\n",
    "  def predict (self, X):\n",
    "    return np.zeros((len(X), 1), dtype=bool)\n",
    "  \n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data)\n",
    "print('### digits data shape', digits.data.shape)\n",
    "print(digits.target)\n",
    "print('### digits target shape', digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target ==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#digit의 번호가 7이면 True이고 이를 1로 변환, 아니면 0\n",
    "y=(digits.target==7).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 크기: (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    411\n",
      "1     39\n",
      "dtype: int64\n",
      "모든 예측을 0으로 해도 정확도는 0.9133\n"
     ]
    }
   ],
   "source": [
    "#불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 테스트 크기:', y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "#더미 분류기로 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "\n",
    "print(f'모든 예측을 0으로 해도 정확도는 {accuracy_score(y_test, fakepred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차행렬 (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[411,   0],\n",
       "       [ 39,   0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "#실제와 가짜 예측결과의 confusion 매트릭스 출력\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정밀도와 재현율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도 : 0.0\n",
      "재현율 : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\conda_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(f'정밀도 : {precision_score(y_test, fakepred)}')\n",
    "print(f'재현율 : {recall_score(y_test, fakepred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "  confusion = confusion_matrix(y_test, pred)\n",
    "  accuracy = accuracy_score(y_test, pred)\n",
    "  precision = precision_score(y_test, pred)\n",
    "  recall = recall_score(y_test, pred)\n",
    "\n",
    "  print('오차행렬')\n",
    "  print(confusion)\n",
    "  print(f'정확도 : {accuracy:.4f}, 정밀도 : {precision:.4f}, 재현율 : {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[81 25]\n",
      " [22 51]]\n",
      "정확도 : 0.7374, 정밀도 : 0.6711, 재현율 : 0.6986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\conda_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#원본데이터 로딩, 데이터 분할\n",
    "titanic_df = pd.read_csv('./data_set/titanic_train.csv')\n",
    "y_df = titanic_df['Survived']\n",
    "x_df = titanic_df.drop('Survived', axis=1)\n",
    "x_df = transform_feature(x_df)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=44)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision / Recall Trade-Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
